{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNol5zj1c1GLNn24zjRwmYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/workspace/blob/main/ASR01/ASR01_textprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A passage to sentences"
      ],
      "metadata": {
        "id": "azaUUb_lfGq6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ekaSLLyIfF16"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "from nltk import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DErDmLGNf2Ss",
        "outputId": "13659d34-f827-4454-f9c9-9291536d51de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passage = \"\"\"When the sunlight strikes raindrops in the air, they act as a prism and form a rainbow. \\\n",
        "The rainbow is a division of white light into many beautiful colors. \\\n",
        "These take the shape of a long round arch, with its path high above, and its two ends apparently \\\n",
        "beyond the horizon. There is, according to legend, a boiling pot of gold at one end. \\\n",
        "People look, but no one ever finds it. When a man looks for something beyond his \\\n",
        "reach, his friends say he is looking for the pot of gold at the end of the rainbow.\\\n",
        "Throughout the centuries people have explained the rainbow in various ways. \\\n",
        "Some have accepted it as a miracle without physical explanation. To the Hebrews it was a \\\n",
        "token that there would be no more universal floods. The Greeks used to imagine that \\\n",
        "it was a sign from the gods to foretell war or heavy rain. The Norsemen considered \\\n",
        "the rainbow as a bridge over which the gods passed from earth to their home in the \\\n",
        "sky. Others have tried to explain the phenomenon physically. Aristotle thought that \\\n",
        "the rainbow was caused by reflection of the sun's rays by the rain. Since then \\\n",
        "physicists have found that it is not reflection, but refraction by the raindrops which \\\n",
        "causes the rainbows. Many complicated ideas about the rainbow have been formed. \\\n",
        "The difference in the rainbow depends considerably upon the size of the drops, and \\\n",
        "the width of the colored band increases as the size of the drops increases. The actual \\\n",
        "primary rainbow observed is said to be the effect of super-imposition of a number of \\\n",
        "bows. If the red of the second bow falls upon the green of the first, the result is to give \\\n",
        "a bow with an abnormally wide yellow band, since red and green light when mixed \\\n",
        "form yellow. This is a very common type of bow, one showing mainly red and \\\n",
        "yellow, with little or no green or blue.\"\"\""
      ],
      "metadata": {
        "id": "18kbMg0XfN51"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slist = sent_tokenize(passage)\n",
        "len(slist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EIEafjMg0g2",
        "outputId": "d247e46c-3588-499f-fcf9-f4b5a2ad581e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe with two columns: Sentence Number (SN) and Sentences (Sentence)\n",
        "sn = []\n",
        "\n",
        "for i in range(0,18):\n",
        "  n = i+1\n",
        "  ns = str(n)\n",
        "  s = \"S\"+ns\n",
        "  sn.append(s)\n",
        "print(sn)\n",
        "\n",
        "sent = slist\n",
        "df = pd.DataFrame()\n",
        "\n",
        "df['SN'] = sn\n",
        "df['Sentence'] = sent\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "UfihjFVEhWfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df = SN, Sentence (length = 18)"
      ],
      "metadata": {
        "id": "ieq7i6Zrjrdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text tokenize to gather word information"
      ],
      "metadata": {
        "id": "aTcdY7oosqvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "text = passage.lower()\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "wordlist = tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "UPEqySnmtL8L"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(wordlist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "595YMO-yjviw",
        "outputId": "45457cac-a325-4177-b5b2-1a39fce2ed45"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "331"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency Distribution\n",
        "fdist = nltk.FreqDist(wordlist)\n",
        "print(fdist)\n",
        "fd = fdist.most_common()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjErzku9ucTx",
        "outputId": "917be23b-a468-4e3d-ff03-f3913e99923d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 176 samples and 331 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VriHaF8xs31E",
        "outputId": "48a96296-a3da-48be-f76e-360406e0c4e9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wlist = []\n",
        "freq = []\n",
        "\n",
        "for i in range(0,len(fd)):\n",
        "  item = fd[i]\n",
        "  w = item[0]\n",
        "  f = item[1]\n",
        "  wlist.append(w)\n",
        "  freq.append(f)\n",
        "\n",
        "df1 = pd.DataFrame()\n",
        "df1['Word'] = wlist\n",
        "df1['Freq'] = freq\n",
        "\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "6COheMFps8Mh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}